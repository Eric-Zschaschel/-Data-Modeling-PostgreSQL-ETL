{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Faster etl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The official documentation for PostgreSQL features an entire section on [Populating a Database](https://www.postgresql.org/docs/current/populate.html#POPULATE-COPY-FROM). According to the documentation, the best way to load data into a database is using the `copy` command - this is much faster than the INSERT. Therefore I created this etl to do exactly that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from typing import Iterator, Dict, Any, Optional\n",
    "from sql_queries import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=sparkifydb user=student password=student\")\n",
    "cur = conn.cursor()\n",
    "conn.set_session(autocommit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# get all files matching extension from directory\n",
    "def get_files(filepath):\n",
    "    all_files = []\n",
    "    # walk() generates the file names in a directory tree\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        # glob finds all the pathnames matching a specified pattern\n",
    "        # join combines the two path elements\n",
    "        files = glob.glob(os.path.join(root, '*.json'))\n",
    "        for f in files:\n",
    "            # add the absolute path to the list\n",
    "            all_files.append(os.path.abspath(f))\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The String Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "thanks to the [beer iterator](https://hakibenita.com/fast-load-data-python-postgresql#copy-data-from-a-string-iterator)\n",
    "the following class creates a file-like object that will act as a buffer between the remote source and the COPY command. The buffer will consume JSON via the iterator, clean and transform the data, and output clean CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StringIteratorIO(io.TextIOBase):\n",
    "    def __init__(self, iter: Iterator[str]):\n",
    "        self._iter = iter\n",
    "        self._buff = ''\n",
    "\n",
    "    def readable(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def _read1(self, n: Optional[int] = None) -> str:\n",
    "        while not self._buff:\n",
    "            try:\n",
    "                self._buff = next(self._iter)\n",
    "            except StopIteration:\n",
    "                break\n",
    "        ret = self._buff[:n]\n",
    "        self._buff = self._buff[len(ret):]\n",
    "        return ret\n",
    "\n",
    "    def read(self, n: Optional[int] = None) -> str:\n",
    "        line = []\n",
    "        if n is None or n < 0:\n",
    "            while True:\n",
    "                m = self._read1()\n",
    "                if not m:\n",
    "                    break\n",
    "                line.append(m)\n",
    "        else:\n",
    "            while n > 0:\n",
    "                m = self._read1(n)\n",
    "                if not m:\n",
    "                    break\n",
    "                n -= len(m)\n",
    "                line.append(m)\n",
    "        return ''.join(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Internally, it fetches the rows from only when its internal line buffer is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Clean Values\n",
    "Empty values are transformed to `\\N`. It is the default string used by PostgreSQL to indicate NULL in `COPY` (this can be changed using the NULL option)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_csv_value(value: Optional[Any]) -> str:\n",
    "    if value is None:\n",
    "        return r'\\N'\n",
    "    if value == 'NaN':\n",
    "        return r'\\N'\n",
    "    return str(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The json file generator\n",
    "Create a generator that reads a list of data paths and loads each json file as a dictionary.\n",
    "If a json file has multiple dictionaries inside, it yields them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def json_gen(file_list: list) -> Iterator[Dict[str, Any]]:\n",
    "    import json\n",
    "    for file in file_list:    \n",
    "        with open(file) as json_file: \n",
    "            data = []\n",
    "            for line in json_file:\n",
    "                data = json.loads(line)\n",
    "                if not data:\n",
    "                    break\n",
    "                yield data\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## json to PostgreSQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_songs(cur, conn, datapath: str) -> None:\n",
    "    file_list = get_files(datapath)\n",
    "    jsonfile = json_gen(file_list)\n",
    "    x = StringIteratorIO((\n",
    "        '|'.join(map(clean_csv_value, (\n",
    "            i['song_id'],\n",
    "            i['title'],\n",
    "            i['artist_id'],\n",
    "            i['year'],\n",
    "            i['duration']\n",
    "        ))) + '\\n'\n",
    "        for i in jsonfile if i['song_id'] != ''\n",
    "    ))\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS tmp_songs;\n",
    "                SELECT * INTO tmp_songs FROM songs;\"\"\")\n",
    "    cur.copy_from(x, 'tmp_songs', sep='|')\n",
    "    cur.execute(\"\"\"INSERT INTO songs (song_id, title, artist_id, year, duration)\n",
    "                SELECT song_id, title, artist_id, year, duration FROM tmp_songs\n",
    "                ON CONFLICT (song_id) DO NOTHING\n",
    "                ON CONFLICT (artist_id) ;\n",
    "                DROP TABLE tmp_songs;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(71,)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getcwd returns current working directory\n",
    "#normcase normalizes the path because windows slashes\n",
    "datapath = os.path.normcase(os.getcwd()) + '/data/song_data'\n",
    "process_songs(cur, conn, datapath)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(song_id) FROM songs LIMIT 5;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_artists(datapath: str) -> None:\n",
    "    file_list = get_files(datapath)\n",
    "    jsonfile = json_gen(file_list)\n",
    "    x = StringIteratorIO((\n",
    "        '|'.join(map(clean_csv_value, (\n",
    "            i['artist_id'],\n",
    "            i['artist_name'],\n",
    "            i['artist_location'],\n",
    "            i['artist_latitude'],\n",
    "            i['artist_longitude']\n",
    "        ))) + '\\n'\n",
    "        for i in jsonfile if i['artist_id'] != ''\n",
    "    ))\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS tmp_artists;\n",
    "                SELECT * INTO tmp_artists FROM artists;\"\"\")\n",
    "    cur.copy_from(x, 'tmp_artists', sep='|')\n",
    "    cur.execute(\"\"\"INSERT INTO artists (artist_id, name, location, latitude, longitude)\n",
    "                SELECT artist_id, name, location, latitude, longitude FROM tmp_artists\n",
    "                ON CONFLICT (artist_id) DO NOTHING;\n",
    "                DROP TABLE tmp_artists;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(69,)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getcwd returns current working directory\n",
    "#normcase normalizes the path because windows slashes\n",
    "datapath = os.path.normcase(os.getcwd()) + '/data/song_data'\n",
    "process_artists(datapath)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(artist_id) from artists;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def json_gen_time(file_list: list) -> Dict[str, Any]:\n",
    "    for file in file_list:    \n",
    "        df = pd.read_json(file, lines=True)\n",
    "        df = df.loc[df['page'] == 'NextSong']\n",
    "        df['ts']= pd.to_datetime(df['ts'], unit = 'ms')\n",
    "        \n",
    "        t = df['ts']\n",
    "        t.drop_duplicates(inplace=True)\n",
    "        t.dropna(inplace=True)\n",
    "        \n",
    "        time_df = pd.DataFrame(index=t.index)\n",
    "        time_df['start_time'] = t\n",
    "        time_df['hour'] = t.dt.hour\n",
    "        time_df['day'] = t.dt.day\n",
    "        time_df['week'] = t.dt.weekofyear\n",
    "        time_df['month'] = t.dt.month\n",
    "        time_df['year'] = t.dt.year\n",
    "        time_df['weekday'] = t.dt.weekday\n",
    "\n",
    "        for index, row in time_df.iterrows():\n",
    "            data = row.to_dict()\n",
    "            yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_time(datapath: str) -> None:\n",
    "    file_list = get_files(datapath)\n",
    "    jsonfile = json_gen_time(file_list)\n",
    "    x = StringIteratorIO((\n",
    "        '|'.join(map(clean_csv_value, (\n",
    "            i['start_time'],\n",
    "            i['hour'],\n",
    "            i['day'],\n",
    "            i['week'],\n",
    "            i['month'],\n",
    "            i['year'],\n",
    "            i['weekday']\n",
    "        ))) + '\\n'\n",
    "        for i in jsonfile if i['start_time'] != ''\n",
    "    ))\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS tmp_time;\n",
    "                SELECT * INTO tmp_time FROM time;\"\"\")\n",
    "    cur.copy_from(x, 'tmp_time', sep='|')\n",
    "    cur.execute(\"\"\"INSERT INTO time (start_time, hour, day, week, month, year, weekday)\n",
    "                SELECT start_time, hour, day, week, month, year, weekday FROM tmp_time\n",
    "                ON CONFLICT (start_time) DO NOTHING;\n",
    "                DROP TABLE tmp_time;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(6813,)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.normcase(os.getcwd()) + '/data/log_data'\n",
    "process_time(datapath)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(start_time) from time;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_users(datapath: str) -> None:\n",
    "    file_list = get_files(datapath)\n",
    "    jsonfile = json_gen(file_list)\n",
    "    x = StringIteratorIO((\n",
    "        '|'.join(map(clean_csv_value, (\n",
    "            i['userId'],\n",
    "            i['firstName'],\n",
    "            i['lastName'],\n",
    "            i['gender'],\n",
    "            i['level']\n",
    "        ))) + '\\n'\n",
    "        for i in jsonfile if i['userId'] != ''\n",
    "    ))\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS tmp_users;\n",
    "                SELECT * INTO tmp_users FROM users;\"\"\")\n",
    "    cur.copy_from(x, 'tmp_users', sep='|')\n",
    "    cur.execute(\"\"\"INSERT INTO users (user_id, first_name, last_name, gender, level)\n",
    "                SELECT user_id, first_name, last_name, gender, level FROM tmp_users \n",
    "                WHERE user_id IS NOT NULL AND user_id <> 0\n",
    "                ON CONFLICT (user_id) DO NOTHING;\n",
    "                DROP TABLE tmp_users;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(97,)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.normcase(os.getcwd()) + '/data/log_data'\n",
    "process_users(datapath)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(user_id) from users;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After some A/B testing I figured out that a query for songid and artistid \n",
    "inside the StringIterator x does not work as x will be used in copy_from.\n",
    "\n",
    "My solution: Doing the filtering after copy_from.\n",
    "I also widened the songlist table for analytical purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_songplays(datapath: str) -> None:\n",
    "    from datetime import datetime\n",
    "    file_list = get_files(datapath)\n",
    "    jsonfile = json_gen(file_list)\n",
    "    \n",
    "    def string_iterator(jsonfile):\n",
    "        for i in jsonfile:\n",
    "            if not i['userId']:\n",
    "                continue\n",
    "            if not i['ts']:\n",
    "                continue\n",
    "           \n",
    "            y = '|'.join(map(clean_csv_value, (\n",
    "                datetime.fromtimestamp(i['ts']/1000.0),\n",
    "                i['userId'],\n",
    "                i['level'],\n",
    "                r'\\N', #songid\n",
    "                r'\\N', #artistid\n",
    "                i['sessionId'], \n",
    "                i['location'],\n",
    "                i['userAgent'],\n",
    "                i['song'],\n",
    "                i['artist'],\n",
    "                i['length']\n",
    "            ))) + '\\n'\n",
    "            yield y\n",
    "   \n",
    "    x = StringIteratorIO(string_iterator(jsonfile))\n",
    "    cur.execute(\"\"\"DROP TABLE IF EXISTS tmp_songplays;\n",
    "                ALTER TABLE songplays \n",
    "                ADD COLUMN song VARCHAR,\n",
    "                ADD COLUMN artist VARCHAR, \n",
    "                ADD COLUMN length DOUBLE PRECISION;\n",
    "                SELECT * INTO tmp_songplays FROM songplays; \n",
    "                \"\"\")\n",
    "    cur.copy_from(x, 'tmp_songplays', sep='|')\n",
    "    cur.execute(\"\"\"INSERT INTO songplays (start_time, user_id, level, \n",
    "                song_id, artist_id, session_id, location, user_agent, \n",
    "                song, artist, length) \n",
    "                SELECT g.start_time, g.user_id, g.level, h.song_id, \n",
    "                h.artist_id, g.session_id, g.location, g.user_agent, \n",
    "                g.song, g.artist, g.length FROM tmp_songplays g\n",
    "                LEFT JOIN (\n",
    "                    SELECT song_id, j.artist_id, k.name as artist, title, \n",
    "                    duration FROM songs j INNER JOIN artists k \n",
    "                    ON j.artist_id = k.artist_id) h ON g.song = h.title \n",
    "                    AND g.length = h.duration AND g.artist = h.artist\n",
    "                ON CONFLICT (start_time, user_id) DO NOTHING;\n",
    "                DROP TABLE tmp_songplays;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7752,)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = os.path.normcase(os.getcwd()) + '/data/log_data'\n",
    "process_songplays(datapath)\n",
    "\n",
    "cur.execute(\"SELECT COUNT(start_time) from songplays;\")\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Close Connection to Sparkify Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
